{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Load Required Libraries**"
      ],
      "metadata": {
        "id": "OX9NgxF9aoKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from pytube import YouTube \n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "import ffmpeg\n",
        "import torch\n",
        "import os\n",
        "import math\n",
        "import yaml\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "import pandas as pd\n",
        "import datetime\n",
        "from moviepy.video.io.ffmpeg_tools import ffmpeg_extract_subclip\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "VKJEzbLRar80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "66cVon1ma28Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset**"
      ],
      "metadata": {
        "id": "babMFXBPbDcm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the csv file with YouTube links for Synthetic videos\n",
        "df_videos_url = pd.read_csv(\"/content/drive/MyDrive/Thesis/Dataset/SyntheticVideoLinks.csv\", sep=\",\")"
      ],
      "metadata": {
        "id": "o_rtADHka5_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the csv file with YouTube links for real-time videos\n",
        "df_real_url = pd.read_csv(\"/content/drive/MyDrive/Thesis/Dataset/RealScenariosVideoLinks.csv\", sep=\",\")"
      ],
      "metadata": {
        "id": "_GcdsdNwdrmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the synthetic videos dataset into train, validation and test data**"
      ],
      "metadata": {
        "id": "0pAB-V7PbLtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train, validation and test sets\n",
        "def split_dataset(df_dataset):\n",
        "\n",
        "  # use the train test split library from sklearn to split data into train and test set.\n",
        "  train_data, test_data = train_test_split(df_dataset, test_size = 0.40, shuffle = True, random_state = 100)\n",
        "  \n",
        "  # use the test set to further split the data into test and validation set.\n",
        "  test_data, validation_data = train_test_split(test_data, test_size = 0.20, random_state = 200)\n",
        "\n",
        "  return train_data, validation_data, test_data"
      ],
      "metadata": {
        "id": "fdb8zmk3bHrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train test and validation sets\n",
        "train_videos, validation_videos, test_videos = split_dataset(df_videos_url)"
      ],
      "metadata": {
        "id": "HQMuqvgdbg0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Download the YouTube videos**"
      ],
      "metadata": {
        "id": "nslqgYD-blEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_youtube_videos(dataset_url,base_download_path, setType):\n",
        "\n",
        "  count = 1  \n",
        "  for url in dataset_url[\"Url\"]:\n",
        "    time.sleep(2)   \n",
        "    youtube_obj = YouTube(url)  \n",
        "    try:\n",
        "      youtube_obj.streams.filter(progressive = True, \n",
        "                                 file_extension = \"mp4\").first().download(output_path = base_download_path + setType, \n",
        "                                                                          filename = f\"VideoInput{setType}{count}.mp4\")\n",
        "      count = count + 1    \n",
        "    except:\n",
        "        print(\"Error downloading video: \", url)\n",
        "  \n",
        "  print(\"Completed - Videos downloaded for \" + setType + \" dataset\")"
      ],
      "metadata": {
        "id": "9kkPf3subhl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download videos in synthetic dataset from YouTube\n",
        "base_path = \"/content/drive/MyDrive/Thesis/Dataset/Videos/\"  \n",
        "download_youtube_videos(train_videos, base_path, \"Train\")\n",
        "download_youtube_videos(validation_videos, base_path, \"Validation\")\n",
        "download_youtube_videos(test_videos, base_path, \"Test\")"
      ],
      "metadata": {
        "id": "4ixulazxb3ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download videos in real-time dataset from YouTube\n",
        "real_base_path = \"/content/drive/MyDrive/Thesis/Dataset/\"\n",
        "download_youtube_videos(df_real_url, base_path, \"Real\")"
      ],
      "metadata": {
        "id": "9og-u1kLcLTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Convert input videos to frames**"
      ],
      "metadata": {
        "id": "xhzTcKKdeFYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert YouTube videos to frames at the given frame rate\n",
        "def video_to_frames(ip_path, train_op_path, val_op_path, frames_rate, splitset = False):\n",
        "  count = 1\n",
        "  split_value = math.ceil(len(os.listdir(ip_path)) * 0.6)\n",
        "  out_path = train_op_path\n",
        "  for video_name in os.listdir(ip_path):\n",
        "    if video_name.endswith(\".mp4\"):\n",
        "      if count >= split_value and splitset == True:\n",
        "        out_path = val_op_path\n",
        "      (ffmpeg.input(ip_path+r\"/\"+video_name).filter('fps', fps=frames_rate).output(out_path+r\"/\"+video_name[:-4]+\"Frame%d.jpg\").run())\n",
        "      count = count + 1"
      ],
      "metadata": {
        "id": "Yro7HIHLeCYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert video to frames for synthetic dataset\n",
        "syn_input_file_path = r\"/content/drive/MyDrive/Thesis/Dataset/Videos/Train\"\n",
        "frame_rate = 1\n",
        "train_output_file_path = r\"/content/drive/MyDrive/Thesis/Dataset/Videos/Train/TrainFrames\"\n",
        "val_output_file_path = r\"/content/drive/MyDrive/Thesis/Dataset/Videos/Train/ValFrames\"\n",
        "\n",
        "video_to_frames(syn_input_file_path, train_output_file_path, val_output_file_path, frame_rate, splitset = True)"
      ],
      "metadata": {
        "id": "KLfjTsv-eK7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert video to frames for real scenario videos\n",
        "real_ip_file_path = r\"/content/drive/MyDrive/Thesis/Dataset/Real\"\n",
        "frame_rate = 1\n",
        "real_op_path = r\"/content/drive/MyDrive/Thesis/Dataset/Real/RealVideoFrames\"\n",
        "val_output_file_path = \"\"\n",
        "\n",
        "video_to_frames(real_ip_file_path, real_op_path, val_output_file_path, frame_rate, splitset = False)"
      ],
      "metadata": {
        "id": "2iD_7C4gegJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clone YOLOv5 model repository**"
      ],
      "metadata": {
        "id": "VIT0y900ncIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Thesis/Model\n",
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt"
      ],
      "metadata": {
        "id": "iL31UGt-e1cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change YOLOv5 Data Configurations file**"
      ],
      "metadata": {
        "id": "IVi7NYtMntxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create own data.yml file with custom classes to be detected\n",
        "config = {'path': '/content/drive/MyDrive/Thesis/Dataset/Videos/Train/',\n",
        "         'train': '/content/drive/MyDrive/Thesis/Dataset/Videos/Train/TrainFrames/',\n",
        "          'val': '/content/drive/MyDrive/Thesis/Dataset/Videos/Train/ValFrames/',\n",
        "         'nc': 1,\n",
        "         'names': [\"Accident\"]}\n",
        " \n",
        "with open(\"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\", \"w\") as file:\n",
        "   yaml.dump(config, file, default_flow_style=False)"
      ],
      "metadata": {
        "id": "R8Vb2-nrnlHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change YOLOv5s Model Configurations File**"
      ],
      "metadata": {
        "id": "qXxdiie19AX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@register_line_cell_magic\n",
        "def change_config_file(line,cell):\n",
        "  with open(line,\"w\") as f:\n",
        "    f.write(cell.format(**globals()))"
      ],
      "metadata": {
        "id": "7cEzePL6n2jO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Changed the number of classes. The architecture remains the same\n",
        "%%change_config_file /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml\n",
        "\n",
        "# Parameters\n",
        "nc: 1  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 v6.0 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, C3, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 6, C3, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, C3, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 3, C3, [1024]],\n",
        "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 v6.0 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, C3, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ],
      "metadata": {
        "id": "ti2WoU8M9mXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**\n",
        "<br> **Using Pre-trained Model:**"
      ],
      "metadata": {
        "id": "UyTl8pfYJxKH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 64, Epochs=20, Image size = 640, Freeze Layers = None, Optimizer = SGD, Learning Rate=0.01"
      ],
      "metadata": {
        "id": "h2WUzTpTKKW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 640 --batch 64 --epochs 20 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --weights /content/drive/MyDrive/Thesis/Model/yolov5/yolov5s.pt --device 0 --cache --project /content/drive/MyDrive/Thesis/Results/res2"
      ],
      "metadata": {
        "id": "BUuA-GL7Kzrk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 64, Epochs=20, Image size = 640, Freeze Layers = 9, Optimizer = SGD, Learning Rate=0.01"
      ],
      "metadata": {
        "id": "l4NZpfjXLU3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 640 --batch 64 --epochs 20 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --weights /content/drive/MyDrive/Thesis/Model/yolov5/yolov5s.pt --device 0 --freeze 9 --project /content/drive/MyDrive/Thesis/Results/res1"
      ],
      "metadata": {
        "id": "T0G-rEpQLT7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 64, Epochs=20, Image size = 640, Freeze Layers = 10, Optimizer = SGD, Learning Rate=0.01"
      ],
      "metadata": {
        "id": "GdmDF6UVLsU1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 640 --batch 64 --epochs 20 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --weights /content/drive/MyDrive/Thesis/Model/yolov5/yolov5s.pt --device 0 --freeze 10 --project /content/drive/MyDrive/Thesis/Results/res3"
      ],
      "metadata": {
        "id": "Ftj5Dvy3L2YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 64, Epochs=20, Image size = 640, Freeze Layers = None, Optimizer = Adam, Learning Rate=0.01"
      ],
      "metadata": {
        "id": "_EqJct-tMAyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 640 --batch 64 --epochs 20 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --weights /content/drive/MyDrive/Thesis/Model/yolov5/yolov5s.pt --optimizer \"Adam\" --device 0 --project /content/drive/MyDrive/Thesis/Results/res5"
      ],
      "metadata": {
        "id": "A_W4cDPvL_r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 64, Epochs=20, Image size = 640, Freeze Layers = 9, Optimizer = Adam, Learning Rate=0.01"
      ],
      "metadata": {
        "id": "uzWf0-2iNZRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 640 --batch 64 --epochs 20 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --weights /content/drive/MyDrive/Thesis/Model/yolov5/yolov5s.pt --optimizer \"Adam\" --device 0 --freeze 9 --project /content/drive/MyDrive/Thesis/Results/res6"
      ],
      "metadata": {
        "id": "cJUoSrElNJ-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 128, Epochs=20, Image size = 640, Freeze Layers = None, Optimizer = SGD, Learning Rate=0.01"
      ],
      "metadata": {
        "id": "dDW-bbC8Nkt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 640 --batch 128 --epochs 20 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --weights /content/drive/MyDrive/Thesis/Model/yolov5/yolov5s.pt --device 0 --project /content/drive/MyDrive/Thesis/Results/res4"
      ],
      "metadata": {
        "id": "lUGp0cjJNe56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 64, Epochs=20, Image size = 512, Freeze Layers = None, Optimizer = SGD, Learning Rate=0.01"
      ],
      "metadata": {
        "id": "_g7j4yTZN2J3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 512 --batch 64 --epochs 20 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --weights /content/drive/MyDrive/Thesis/Model/yolov5/yolov5s.pt --device 0 --project /content/drive/MyDrive/Thesis/Results/res4"
      ],
      "metadata": {
        "id": "SvTJPf64OCih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 64, Epochs=20, Image size = 512, Freeze Layers = 9, Optimizer = SGD, Learning Rate=0.01"
      ],
      "metadata": {
        "id": "Ou-ujSQYOPFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 512 --batch 64 --epochs 20 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --weights /content/drive/MyDrive/Thesis/Model/yolov5/yolov5s.pt --device 0 --freeze 9 --project /content/drive/MyDrive/Thesis/Results/res7"
      ],
      "metadata": {
        "id": "NmCi1HGDORq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 64, Epochs=100, Image size = 640, Freeze Layers = 9, Optimizer = SGD, Learning Rate=0.01"
      ],
      "metadata": {
        "id": "eADCi9q1OnA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 640 --batch 64 --epochs 100 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --weights /content/drive/MyDrive/Thesis/Model/yolov5/yolov5s.pt --device 0 --freeze 9 --project /content/drive/MyDrive/Thesis/Results/res8"
      ],
      "metadata": {
        "id": "ZPihPn4iOncQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 64, Epochs=200, Image size = 640, Freeze Layers = 9, Optimizer = SGD, Learning Rate=0.01"
      ],
      "metadata": {
        "id": "egy8qdwTO8xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 640 --batch 64 --epochs 200 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --weights /content/drive/MyDrive/Thesis/Model/yolov5/yolov5s.pt --device 0 --freeze 9 --project /content/drive/MyDrive/Thesis/Results/res9"
      ],
      "metadata": {
        "id": "SL_7kYqjO9JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training from scratch**"
      ],
      "metadata": {
        "id": "eWEgJMvqPMqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 64, Epochs=20, Image size = 640, Optimizer = SGD, Learning Rate=0.01"
      ],
      "metadata": {
        "id": "q_nw4MkrPRMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 640 --batch 64 --epochs 20 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --weights \"\" --device 0 --project /content/drive/MyDrive/Thesis/Results/res10"
      ],
      "metadata": {
        "id": "RW98a84UPLqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 64, Epochs=20, Image size = 640, Optimizer = Adam, Learning Rate=0.01"
      ],
      "metadata": {
        "id": "tajeNXmuPxmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 640 --batch 64 --epochs 20 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --weights \"\" --optimizer \"Adam\" --device 0 --project /content/drive/MyDrive/Thesis/Results/res11"
      ],
      "metadata": {
        "id": "EZWtFARtP3rX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 64, Epochs=100, Image size = 640, Optimizer = SGD, Learning Rate=0.01"
      ],
      "metadata": {
        "id": "Jqsx73E1P-O2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 640 --batch 64 --epochs 100 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --weights \"\" --device 0 --project /content/drive/MyDrive/Thesis/Results/res12"
      ],
      "metadata": {
        "id": "zoav2wvjQHnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-Tuning the best model**"
      ],
      "metadata": {
        "id": "7eYcmgTxQEn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Change YOLOv5s Hyperparameter configuration file**"
      ],
      "metadata": {
        "id": "EAes3MiaRv37"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the learning rate in the hyperparameter config file. Rest of the hyperparameters remain the same.\n",
        "%%change_config_file /content/drive/MyDrive/Thesis/Model/yolov5/data/hyps/custom_hyps.yaml\n",
        "\n",
        "# YOLOv5 🚀 by Ultralytics, GPL-3.0 license\n",
        "# Hyperparameters for low-augmentation COCO training from scratch\n",
        "# python train.py --batch 64 --cfg yolov5n6.yaml --weights '' --data coco.yaml --img 640 --epochs 300 --linear\n",
        "# See tutorials for hyperparameter evolution https://github.com/ultralytics/yolov5#tutorials\n",
        "\n",
        "lr0: 0.001  # initial learning rate (SGD=1E-2, Adam=1E-3)\n",
        "lrf: 0.01  # final OneCycleLR learning rate (lr0 * lrf)\n",
        "momentum: 0.937  # SGD momentum/Adam beta1\n",
        "weight_decay: 0.0005  # optimizer weight decay 5e-4\n",
        "warmup_epochs: 3.0  # warmup epochs (fractions ok)\n",
        "warmup_momentum: 0.8  # warmup initial momentum\n",
        "warmup_bias_lr: 0.1  # warmup initial bias lr\n",
        "box: 0.05  # box loss gain\n",
        "cls: 0.5  # cls loss gain\n",
        "cls_pw: 1.0  # cls BCELoss positive_weight\n",
        "obj: 1.0  # obj loss gain (scale with pixels)\n",
        "obj_pw: 1.0  # obj BCELoss positive_weight\n",
        "iou_t: 0.20  # IoU training threshold\n",
        "anchor_t: 4.0  # anchor-multiple threshold\n",
        "# anchors: 3  # anchors per output layer (0 to ignore)\n",
        "fl_gamma: 0.0  # focal loss gamma (efficientDet default gamma=1.5)\n",
        "hsv_h: 0.015  # image HSV-Hue augmentation (fraction)\n",
        "hsv_s: 0.7  # image HSV-Saturation augmentation (fraction)\n",
        "hsv_v: 0.4  # image HSV-Value augmentation (fraction)\n",
        "degrees: 0.0  # image rotation (+/- deg)\n",
        "translate: 0.1  # image translation (+/- fraction)\n",
        "scale: 0.5  # image scale (+/- gain)\n",
        "shear: 0.0  # image shear (+/- deg)\n",
        "perspective: 0.0  # image perspective (+/- fraction), range 0-0.001\n",
        "flipud: 0.0  # image flip up-down (probability)\n",
        "fliplr: 0.5  # image flip left-right (probability)\n",
        "mosaic: 1.0  # image mosaic (probability)\n",
        "mixup: 0.0  # image mixup (probability)\n",
        "copy_paste: 0.0  # segment copy-paste (probability)\n"
      ],
      "metadata": {
        "id": "91kzMEL4RK56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters:\n",
        "Batch size = 64, Epochs=50, Image size = 640, Optimizer = SGD, Learning Rate=0.001"
      ],
      "metadata": {
        "id": "JhgTZIDPQeDo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/Thesis/Model/yolov5/train.py --img 640 --batch 64 --epochs 50 --data \"/content/drive/MyDrive/Thesis/Model/yolov5/data.yaml\" --cfg /content/drive/MyDrive/Thesis/Model/yolov5/models/custom_yolov5s.yaml --hyp \"/content/drive/MyDrive/Thesis/Model/yolov5/data/hyps/custom_hyps.yaml\" --weights /content/drive/MyDrive/Thesis/Results/res1/exp3/best.pt --device 0 --project /content/drive/MyDrive/Thesis/Results/res13"
      ],
      "metadata": {
        "id": "5n8D7OV8Qb4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Video Summarization**"
      ],
      "metadata": {
        "id": "xxcEaoffSqlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Model with best weights**"
      ],
      "metadata": {
        "id": "6ja70-VoTG0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolo_custom = torch.hub.load('ultralytics/yolov5', 'custom', path='/content/drive/MyDrive/Thesis/Results/res13/exp/weights/best.pt')  # local model"
      ],
      "metadata": {
        "id": "_85yk51oSufU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save details of each frame**"
      ],
      "metadata": {
        "id": "sqVdIfPITULZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will save frame number, duration, model prediction and the confidence score for each frame in the video in a csv file\n",
        "def save_csv(save_directory, video_path):\n",
        "  accident_pred = []\n",
        "  accident_conf = []\n",
        "  frame_position_list = []\n",
        "  frame_duration_list = []\n",
        "  frame_sec_list = []\n",
        "  vidcap = cv2.VideoCapture(video_path)\n",
        "  success,image = vidcap.read()\n",
        "  while success:\n",
        "    frame_index = int(vidcap.get(cv2.CAP_PROP_POS_FRAMES))\n",
        "    frame_sec = round(vidcap.get(cv2.CAP_PROP_POS_MSEC)/1000,2)\n",
        "    frame_duration = str(datetime.timedelta(seconds=frame_sec))\n",
        "    frame_position_list.append(frame_index)\n",
        "    frame_duration_list.append(frame_duration)\n",
        "    frame_sec_list.append(frame_sec)\n",
        "\n",
        "    yolo_result = yolo_custom(image)\n",
        "    if (yolo_result.pandas().xyxy[0].name == \"Accident\").any():\n",
        "      accident_pred.append(\"1\")\n",
        "      accident_conf.append(yolo_result.pandas().xyxy[0].confidence.values[0])\n",
        "    else:\n",
        "      accident_pred.append(\"0\")\n",
        "      accident_conf.append(0)\n",
        "    success,image = vidcap.read()\n",
        "  video_details_df = pd.DataFrame({\"Frame_position\": frame_position_list,\n",
        "                                   \"Time_sec\": frame_sec_list,\n",
        "                                   \"Time\": frame_duration_list,\n",
        "                                   \"Prediction\": accident_pred,\n",
        "                                   \"Confidence\": accident_conf\n",
        "                                   })\n",
        "  video_details_df.to_csv(save_directory + \"/VideoDetails.csv\", index=False, header=True)"
      ],
      "metadata": {
        "id": "_h6kf3f7TMKu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Apply event based video summarization and generate short video clips**"
      ],
      "metadata": {
        "id": "Wnz2IG7XTwmw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will generate short video clips of accidents\n",
        "def generate_videos(save_directory, video_path, csv_path):\n",
        "  csv_details = pd.read_csv(csv_path)\n",
        "  accident_df = csv_details[csv_details[\"Prediction\"] == 1]\n",
        "  frame_pos_details = []\n",
        "  start_frame = accident_df.Frame_position.values[0]\n",
        "  end_frame = accident_df.Frame_position.values[0]\n",
        "\n",
        "  vidcap = cv2.VideoCapture(video_path)\n",
        "  ip_width = int(vidcap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "  ip_height = int(vidcap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "  fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
        "  length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "  accident_frames = accident_df.Frame_position.values.tolist()\n",
        "  accident_sec = accident_df.Time_sec.values.tolist()\n",
        "  font = cv2.FONT_HERSHEY_PLAIN\n",
        "  acc_frame_count = 0\n",
        "  counter = 1\n",
        "\n",
        "  for i in range(len(accident_frames)):\n",
        "    prev_frame = accident_frames[i-1] if i!=0 else accident_frames[0]\n",
        "    if accident_frames[i] >= end_frame and accident_frames[i] - prev_frame <= int(fps):\n",
        "      end_frame = accident_frames[i]\n",
        "      acc_frame_count = acc_frame_count + 1\n",
        "    else:\n",
        "      if (start_frame - int(fps/2)) < 0:\n",
        "        start_frame = 1\n",
        "      else:\n",
        "        start_frame = start_frame - int(fps/2)\n",
        "      \n",
        "      if end_frame + int(fps/2) > length:\n",
        "        end_frame = length\n",
        "      else:\n",
        "        end_frame = end_frame + int(fps/2)\n",
        "\n",
        "      if acc_frame_count > 1:\n",
        "        start_dur = csv_details[csv_details[\"Frame_position\"] == start_frame].Time_sec.values[0]\n",
        "        end_dur = csv_details[csv_details[\"Frame_position\"] == end_frame].Time_sec.values[0]\n",
        "        frame_pos_details.append([start_dur,end_dur])\n",
        "        acc_frame_count = 0\n",
        "      \n",
        "      start_frame = accident_frames[i]\n",
        "  for frame in frame_pos_details:\n",
        "    start_val , end_val = frame\n",
        "    ffmpeg_extract_subclip(video_path, start_val, end_val, targetname= save_directory + f\"/Summary{counter}.mp4\")\n",
        "    counter = counter+1"
      ],
      "metadata": {
        "id": "VHEIM1pJTYso"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/Thesis/Results/RealVideos/\"\n",
        "video_path_val = \"/content/drive/MyDrive/Thesis/Dataset/Real/\"\n",
        "\n",
        "for file in video_path_val:\n",
        "  if file.endswith(\".mp4\"):\n",
        "    summary_op_save_path = save_path + file[:-4]\n",
        "    summary_ip_video_path = video_path_val + \"/\" + file\n",
        "    save_csv(summary_op_save_path, summary_ip_video_path)\n",
        "    generate_videos(summary_op_save_path, summary_op_save_path,save_path+\"/VideoDetails.csv\")\n"
      ],
      "metadata": {
        "id": "6Umj0h0AVdZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Metrics**"
      ],
      "metadata": {
        "id": "sh8l1_FDXO5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_data(confusion_matrix):\n",
        "  ax = sns.heatmap(confusion_matrix, annot=True, cmap='Purples', fmt= \".0f\")\n",
        "  ax.set_title('Confusion Matrix for Synthetic Video 1\\n\\n');\n",
        "  ax.set_xlabel('\\nPredicted Values')\n",
        "  ax.set_ylabel('Actual Values ');\n",
        "\n",
        "  ax.xaxis.set_ticklabels(['Background','Accident'])\n",
        "  ax.yaxis.set_ticklabels(['Background','Accident'])\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "yR4ZwMQ0X2L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluation(model_ground_truth_path, model_predictions_path):\n",
        "  ground_truth_details = pd.read_csv(model_ground_truth_path)\n",
        "  pred_details = pd.read_csv(model_predictions_path)\n",
        "\n",
        "  confusion_matrix = metrics.confusion_matrix(ground_truth_details, pred_details)\n",
        "  plot_data(confusion_matrix)\n",
        "\n",
        "  accuracy = metrics.accuracy_score(ground_truth_details, pred_details)\n",
        "  precision = metrics.precision_score(ground_truth_details, pred_details)\n",
        "  recall = metrics.recall_score(ground_truth_details, pred_details)\n",
        "  f1_score = metrics.f1_score(ground_truth_details, pred_details)\n"
      ],
      "metadata": {
        "id": "4UO4Ev8MXTUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for file in video_path_val:\n",
        "  if file.endswith(\".mp4\"):\n",
        "    gt_path = save_path + file[:-4] + \"/GroundTruth.csv\"\n",
        "    pred_details = video_path_val + \"/\" + file\n",
        "    evaluation(save_path, pred_details)\n"
      ],
      "metadata": {
        "id": "wzL24jSJZEGb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}